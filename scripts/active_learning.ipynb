{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sbi\n",
    "sbi.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNLE, SNPE\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.inference import MCMCPosterior, RejectionPosterior\n",
    "from sbi.utils import mcmc_transform\n",
    "from sbi.inference.potentials.base_potential import BasePotential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import ones, zeros, eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = BoxUniform(-ones(2), ones(2))\n",
    "def sim(theta):\n",
    "    return theta + torch.randn(theta.shape) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcquisitionPotential(BasePotential):\n",
    "    allow_iid_x = False\n",
    "    def __init__(self, prior, x_o, device=\"cpu\"):\n",
    "        super().__init__(prior, x_o, device)\n",
    "    \n",
    "    def __call__(self, theta, track_gradients=True):\n",
    "        return acquisition_fn(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_calibration.loss import StepLoss_weighted\n",
    "loss_fn = StepLoss_weighted([2,1], 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn(true_theta, sampled_theta):\n",
    "#     costs = []\n",
    "#     for s in sampled_theta:\n",
    "#         if true_theta[0, 0] < 0.0:\n",
    "#             if s[0] < 0.0:\n",
    "#                 costs.append(torch.tensor([0.01]))\n",
    "#             else:\n",
    "#                 costs.append(torch.tensor([1.0]))\n",
    "#         else:\n",
    "#             if s[0] > 0.0:\n",
    "#                 costs.append(torch.tensor([0.01]))\n",
    "#             else:\n",
    "#                 costs.append(torch.tensor([1.0]))\n",
    "#     return torch.cat(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_monte_carlo_samples_likelihood = 5\n",
    "num_monte_carlo_samples_posterior = 1\n",
    "\n",
    "    \n",
    "def acquisition_fn(theta_0):\n",
    "    predicted_x = likelihood_estimator.sample(num_monte_carlo_samples_likelihood, context=theta_0)[0] \n",
    "    predicted_theta_given_x = []\n",
    "    for px in predicted_x: #lässt sich der loop eliminieren?\n",
    "        predicted_theta_given_x.append(posterior_estimator.sample(num_monte_carlo_samples_posterior, context=px.unsqueeze(0))[0])\n",
    "    predicted_theta_given_x = torch.cat(predicted_theta_given_x)\n",
    "    predicted_decision = (predicted_theta_given_x > 0.).float()\n",
    "    estimated_cost = loss_fn(theta_0[:,0], predicted_decision[:,0])\n",
    "    #estimated_cost = loss_fn(theta_0, predicted_theta_given_x)\n",
    "    return estimated_cost.mean()\n",
    "\n",
    "# can handle batches: \n",
    "def acquisition_fn_batches(theta_0):\n",
    "    predicted_x = likelihood_estimator.sample(num_monte_carlo_samples_likelihood, context=theta_0) \n",
    "    predicted_theta_given_x = []\n",
    "    for px in predicted_x.swapaxes(0,1): #lässt sich der loop eliminieren? nein, weil posterior_sample nicht mit 3 dim umgehen kann\n",
    "        predicted_theta_given_x.append(posterior_estimator.sample(num_monte_carlo_samples_posterior, context=px))\n",
    "    predicted_theta_given_x = torch.cat(predicted_theta_given_x, dim=1) \n",
    "    predicted_decision = (predicted_theta_given_x > 0.).float()\n",
    "    #estimated_cost = loss_fn(theta_0[:,0].unsqueeze(1).repeat(1,num_monte_carlo_samples_likelihood), predicted_decision[:,:,0])\n",
    "    estimated_cost = loss_fn(theta_0, predicted_theta_given_x)\n",
    "    return estimated_cost.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 10191 epochs."
     ]
    }
   ],
   "source": [
    "n_rounds = 1\n",
    "proposal = prior\n",
    "\n",
    "# inference objects\n",
    "inference_likelihood = SNLE(prior)\n",
    "inference_posterior = SNPE(prior)\n",
    "\n",
    "for r in range(n_rounds): # rounds\n",
    "    theta = proposal.sample((1000,))\n",
    "    x = sim(theta)\n",
    "    # train both SNLE and SNPE\n",
    "    likelihood_estimator = inference_likelihood.append_simulations(theta, x).train(max_num_epochs=100)\n",
    "    posterior_estimator = inference_posterior.append_simulations(theta, x, proposal=proposal).train(max_num_epochs=100)\n",
    "\n",
    "    # potential = AcquisitionPotential(prior, zeros(1, 2), device=\"cpu\")\n",
    "    # prior_tf = mcmc_transform(prior)\n",
    "    # acquisition_sampler = MCMCPosterior(potential_fn=potential, theta_transform=prior_tf, proposal=prior, init_strategy=\"proposal\", method=\"slice_np\")\n",
    "    # proposal = acquisition_sampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can acquisition_fn handle btaches? \n",
    "th_0 = prior.sample((1,))\n",
    "th_0.shape, likelihood_estimator.sample(num_monte_carlo_samples_likelihood, context=th_0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 = prior.sample((3,))\n",
    "theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_x = likelihood_estimator.sample(num_monte_carlo_samples_likelihood, context=theta_0) # shape: context[0], num_samples, context[1]\n",
    "predicted_theta_given_x = []\n",
    "for px in predicted_x.swapaxes(0,1): #lässt sich der loop eliminieren? nein, weil posterior_sample nicht mit 3 dim umgehen kann\n",
    "    # px shape: context[0], context[1]\n",
    "    post_sample = posterior_estimator.sample(num_monte_carlo_samples_posterior, context=px) # shape: context[0], 1, context[1]\n",
    "    predicted_theta_given_x.append(post_sample)\n",
    "predicted_theta_given_x = torch.cat(predicted_theta_given_x, dim=1) # shape: context[0], num_samples, context[1]\n",
    "predicted_decision = (predicted_theta_given_x > 0.).float()\n",
    "estimated_cost = loss_fn(theta_0[:,0].unsqueeze(1).repeat(1,5), predicted_decision[:,:,0])\n",
    "print(\"estimated_cost\", estimated_cost)\n",
    "print(\"mean\", estimated_cost.mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition_fn(theta_0):\n",
    "    print(\"theta_0\", theta_0.shape)\n",
    "    predicted_x = likelihood_estimator.sample(num_monte_carlo_samples_likelihood, context=theta_0)[0]\n",
    "    print(\"predicted_x\", predicted_x.shape)\n",
    "    predicted_theta_given_x = []\n",
    "    for px in predicted_x: #lässt sich der loop eliminieren?\n",
    "        predicted_theta_given_x.append(posterior_estimator.sample(num_monte_carlo_samples_posterior, context=px.unsqueeze(0))[0])\n",
    "    predicted_theta_given_x = torch.cat(predicted_theta_given_x)\n",
    "    predicted_decision = (predicted_theta_given_x > 0.).float()\n",
    "    estimated_cost = loss_fn(theta_0[:,0], predicted_decision[:,0])\n",
    "    print(theta_0[:,0].shape, predicted_decision[:,0].shape)\n",
    "    print(\"estimated_cost\", estimated_cost.shape)\n",
    "    return estimated_cost.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in theta_0[:1]:\n",
    "    print(acquisition_fn(th.unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each theta, likelihood_estimator samples n samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_0 = prior.sample((1,))\n",
    "xx = likelihood_estimator.sample(5, context=th_0)\n",
    "print(\"xx\", xx.shape)\n",
    "for x in xx.swapaxes(0,1):\n",
    "    th = posterior_estimator.sample(1, context=x) # loop over dim 1 (all x)\n",
    "    print(\"x\", x.shape)\n",
    "    print(\"th\", th.squeeze(dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_estimator.sample(1, context=xx[:,1,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential = AcquisitionPotential(prior, zeros(1, 2), device=\"cpu\")\n",
    "prior_tf = mcmc_transform(prior)\n",
    "acquisition_sampler = MCMCPosterior(potential_fn=potential, theta_transform=prior_tf, proposal=prior, init_strategy=\"proposal\", method=\"slice_np\")#, num_chains=100)\n",
    "# proposal = prior oder proposal = proposal??\n",
    "# MCMCPosterior gegen RejectionPosterior tauschen, ggf. schneller\n",
    "# wenn acquisition_fn+loss_fn vectorized, use method = slice_np_vectorized + num_cahins = 100\n",
    "proposal = acquisition_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes dont fit\n",
    "# aa = torch.linspace(-1,1,100)\n",
    "# plt.plot(aa, torch.cat([potential(a.unsqueeze(0).unsqueeze(0)).unsqueeze(0) for a in aa]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...: 100%|██████████| 50/50 [00:21<00:00,  2.29it/s]\n",
      "Generating samples: 100%|██████████| 10/10 [00:21<00:00,  2.15s/it]\n",
      "Generating samples: 100%|██████████| 10/10 [00:20<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "samples = proposal.sample((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample tensor([-0.0280,  0.4252]) \tpotential 0.600\n",
      "sample tensor([-0.1584,  0.5626]) \tpotential 0.400\n",
      "sample tensor([0.5919, 0.1166]) \tpotential 0.000\n",
      "sample tensor([ 0.6887, -0.7672]) \tpotential 0.000\n",
      "sample tensor([-0.0179, -0.6287]) \tpotential 0.600\n",
      "sample tensor([ 0.3792, -0.7839]) \tpotential 0.400\n",
      "sample tensor([-0.3888, -0.3527]) \tpotential 0.000\n",
      "sample tensor([0.3166, 0.9095]) \tpotential 0.000\n",
      "sample tensor([0.1044, 0.4243]) \tpotential 1.200\n",
      "sample tensor([ 0.1350, -0.6208]) \tpotential 0.000\n"
     ]
    }
   ],
   "source": [
    "for aa in samples:\n",
    "    print(f\"sample {aa} \\tpotential {potential(aa.unsqueeze(0)).item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_samples = prior.sample((10,))\n",
    "# for aa in prior_samples:\n",
    "#     print(\"prior\", potential(aa.unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potentials:  [0.6, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.4, 0.8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_potentials = [potential(aa.unsqueeze(0)).item()  for aa in samples]\n",
    "prior_potentials = [potential(aa.unsqueeze(0)).item()  for aa in prior_samples]\n",
    "print(\"potentials: \", list(map(lambda p: round(p,3), samples_potentials)))\n",
    "plt.scatter(samples[:,0], samples_potentials)\n",
    "plt.scatter(prior_samples[:,0], prior_potentials)\n",
    "plt.xlabel('first element of samples')\n",
    "plt.xlabel('potential')\n",
    "plt.vlines(0.0, ymin=-0.05, ymax=max(samples_potentials+prior_potentials)+0.05, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06960cd18a53001e07e7b62cc42eb3f51084fa348611365b68962d25c7d940d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
